{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d528fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize a session\n",
    "session = requests.Session()\n",
    "\n",
    "# Define the base URL and other parameters\n",
    "base_url = \"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg\"\n",
    "search_query = \"bags\"\n",
    "num_pages_to_scrape = 20\n",
    "\n",
    "# Initialize empty lists to store scraped data\n",
    "product_urls = []\n",
    "product_names = []\n",
    "product_prices = []\n",
    "ratings = []\n",
    "num_reviews = []\n",
    "\n",
    "# Loop through the desired number of pages\n",
    "for page_num in range(1, num_pages_to_scrape + 1):\n",
    "    # Define the query parameters for the URL\n",
    "    params = {\n",
    "        \"k\": search_query,\n",
    "        \"page\": page_num\n",
    "    }\n",
    "\n",
    "    # Make a request to the page\n",
    "    response = session.get(base_url, params=params)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find product details on the page\n",
    "    products = soup.find_all(\"div\", class_=\"s-result-item\")\n",
    "\n",
    "    # Extract information from each product\n",
    "    for product in products:\n",
    "        # Extract product URL\n",
    "        product_link = product.find(\"a\", class_=\"a-link-normal s-no-outline\")\n",
    "        if product_link:\n",
    "            product_urls.append(\"https://www.amazon.in\" + product_link[\"href\"])\n",
    "        \n",
    "        # Extract product name\n",
    "        product_name = product.find(\"span\", class_=\"a-text-normal\")\n",
    "        if product_name:\n",
    "            product_names.append(product_name.get_text(strip=True))\n",
    "        \n",
    "        # Extract product price\n",
    "        product_price = product.find(\"span\", class_=\"a-price-whole\")\n",
    "        if product_price:\n",
    "            product_prices.append(product_price.get_text(strip=True))\n",
    "        \n",
    "        # Extract product rating\n",
    "        rating = product.find(\"span\", class_=\"a-icon-alt\")\n",
    "        if rating:\n",
    "            ratings.append(rating.get_text(strip=True))\n",
    "        \n",
    "        # Extract number of reviews\n",
    "        num_review = product.find(\"span\", class_=\"a-size-base\")\n",
    "        if num_review:\n",
    "            num_reviews.append(num_review.get_text(strip=True))\n",
    "\n",
    "# Print the scraped data for verification\n",
    "# for i in range(len(product_urls)):\n",
    "#     print(\"Product URL:\", product_urls[i])\n",
    "#     print(\"Product Name:\", product_names[i])\n",
    "#     print(\"Product Price:\", product_prices[i])\n",
    "#     print(\"Rating:\", ratings[i])\n",
    "#     print(\"Number of Reviews:\", num_reviews[i])\n",
    "#     print(\"=\"*50)\n",
    "\n",
    "# Close the session\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78fd945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
